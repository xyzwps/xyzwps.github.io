---
layout: ../../../layouts/MdxLayout.astro
title: 速率限制模式
parent:
  name: 返回上级
  path: /cheatsheet/cloud-patterns/
translateFrom:
  url: https://learn.microsoft.com/en-us/azure/architecture/patterns/rate-limiting-pattern
  title: Rate Limiting pattern - Azure Architecture Center
---

TODO: 翻译很烂

许多服务使用[节流模式](/cheatsheet/cloud-patterns/throttling)来控制它们消耗的资源，
对其他应用程序或服务访问它们的速率施加限制。
您可以使用速率限制模式来帮助您避免或最小化与这些限制相关的限制错误，并帮助您更准确地预测吞吐量。

速率限制模式适用于许多场景，对于大规模重复性自动化任务（如批次处理作业）特别有用。

## 问题上下文

使用受限制的服务执行大量操作可能会导致流量和吞吐量增加，您需要跟踪被拒绝的请求，然后重试这些操作。
随着操作数量的增加，限制可能需要多次重新发送数据，从而产生更大的性能影响。

举个例子。考虑以下将数据写入 Azure Cosmos DB 的简单重试错误过程：

1. 你的应用程序需要将 1 万条记录写入到 Azure Cosmos DB 中。
   摄取每条记录需要 10 个请求单元（RU），总共需要 1 万个 RU 才能完成这项工作。

2. 你的 Azure Cosmos DB 实例具有 2 万个 RU 的预配容量。

3. 你把所有 1 万条记录发送到 Azure Cosmos DB。成功写入 2 千条记录，拒绝 8 千条记录。

4. 你把剩余的 8 千条记录发送到 Azure Cosmos DB。成功写入 2 千条记录，拒绝 6 千条记录。

5. 你把剩余的 6 千条记录发送到 Azure Cosmos DB。成功写入 2 千条记录，拒绝 4 千条记录。

6. 你把剩余的 4 千条记录发送到 Azure Cosmos DB。成功写入 2 千条记录，拒绝 2 千条记录。

7. 你把剩余的 2 千条记录发送到 Azure Cosmos DB。全部写入成功。

写入任务成功完成，但仅在将 3 万条记录发送到 Azure Cosmos DB 之后，即使整个数据集仅包含 1 万条记录。

在上面的例子中还有其他因素需要考虑：

- 大量错误导致记录了大量错误和处理错误的日志。
  这种简单的方法将处理 2 万个错误，记录这些错误可能会增加处理、内存或存储资源成本。
- 不知道写入服务的限制，这种朴素的方法就无法设置数据处理需要多长时间的期望。
  速率限制可以让您计算摄取所需的时间。

## 解决方案

速率限制可以通过减少在给定时间段内发送到服务的记录数量，来减少流量并潜在地提高吞吐量。

随着时间的推移，服务可能会根据不同的指标进行限制，例如：

- 操作数量（比如 20 QPS）
- 数据量（比如 2GiB 每分钟）
- 相对操作成本（比如 2 万 RU 每秒）

无论用于节流的度量标准如何，你的速率限制实现，都会涉及控制在特定时间段内发送到服务的操作的数量和/或大小，
优化您对服务的使用，同时不超过其节流能力。

如果 API 处理请求的速度，比任何受限制的写入服务允许的速度都快，你就需要管理使用该服务的速度。
如果只把限制用与解决数据速率不匹配问题，并简单地缓冲您的写入请求，直到受限制的服务能够赶上，是有风险的。
如果您的应用程序在这种情况下崩溃，您就有丢失任何这些缓冲数据的风险。

为避免这种风险，请考虑将记录发送到持久性的消息系统，来覆盖全部写入率。
然后，你可以使用一个或多个作业处理器，以受限制服务限制内的受控速率从消息传递系统读取记录。
把记录提交到消息系统，只在给定时间内消费能够处理的部分记录，还可以节省内存。

当你发送记录时，用于释放记录的时间段，可能比服务限制的时间段更细粒度。
系统通常根据您可以轻松理解和使用的时间跨度设置限制。
然而，对于运行服务的计算机来说，与处理信息的速度相比，这些时间帧可能很长。
例如，系统可能每秒或每分钟节流，但通常代码的处理时间是纳秒或毫秒。

虽然不是必需的，但通常建议更频繁地发送更少量的记录以提高吞吐量。
因此，您可以更精细地保持资源消耗（内存、CPU、网络等）以更均匀的速率流动，
而非每秒或每分钟尝试一次批量发布，从而防止由于请求突然爆发而导致的潜在瓶颈。
例如，如果一个服务每秒允许 100 次操作，则速率限制器的实现可以通过每 200 毫秒释放 20 次操作来平衡请。

此外，多个不协调的进程有时需要共享一个受限制的服务。
要在这种情况下实现速率限制，您可以对服务的容量进行逻辑分区，然后使用分布式互斥系统来管理这些分区上的独占锁。
然后，不协调的进程可以在需要容量时争夺这些分区上的锁。对于进程持有锁的每个分区，它被授予一定数量的容量。

例如，如果受限制的系统每秒允许 500 个请求，您可以创建 20 个分区，每个分区每秒 25 个请求。
如果一个进程需要发出 100 个请求，它可能会向分布式互斥系统请求四个分区。
系统可能会授予两个分区 10 秒。然后，该进程将速率限制为每秒 50 个请求，在两秒内完成任务，然后释放锁。

为了进一步减少延迟，您可以为每个进程分配少量独占容量。
只有当一个进程需要超过其预留容量时，它才会寻求获得共享容量的租约。

您可以使用 Azure Storage、Zookeeper、Consul、etcd、[Redis/Redsync](https://github.com/go-redsync/redsync)
等技术来实现这种租赁管理系统。

## 实现考量

实现此模式时应考虑以下几点：

- 虽然速率限制模式可以减少限制错误的数量，但您的应用程序仍然需要正确处理可能发生的任何限制错误。

- 如果您的应用程序有多个工作流访问相同的受限制服务，您需要将所有这些都集成到您的速率限制策略中。
  例如，您可能支持将记录批量加载到数据库中，但也可以查询同一数据库中的记录。
  您可以通过确保所有工作流都通过相同的速率限制机制进行门控来管理容量。或者，您可以为每个工作流保留单独的容量池。

- 受限制的服务可能在多个应用程序中使用。在某些（但不是所有）情况下，可以协调使用。
  如果您开始看到比预期数量更多的限制错误，这可能是访问服务的应用程序之间争用的迹象。
  如果是这样，您可能需要考虑暂时降低速率限制机制施加的吞吐量，直到其他应用程序的使用降低。

  ## 何时使用

  以下场景可以使用：

  - 减少节流错误。
  - 减少重试错误路径分支的流量。
  - 仅在有能力处理记录时再将记录取出来，以减少内存消耗。