---
layout: ./BlogLayout.astro
title: BM25 算法
---

[Understanding TF-IDF and BM-25 - KMW](https://kmwllc.com/index.php/2020/03/20/understanding-tf-idf-and-bm-25/)
此文写得很不错，我就干脆直接搬运过来好了。英文好的你可以尝试去看原文。

## 介绍

如果你是搜索从业者，并且希望深入理解排分函数（_ranking function_）TF-IDF 和 BM25（在 Lucense 中也称为“相似度”），
那么本文就是为你写哒。如果你像很多从业者那样，已经熟悉了 TF-IDF，但是在你第一次看见复杂的 BM25 公式时，你想“以后再说吧”，
那么现在就是合适的时间去理解它了！你也可能已经听说过 BM25，它和 TF-IDF 类似，但是它在实践中的表现更好。
本文会向你展示 BM25 是如何构建在 TF-IDF 智商的，它的参数的用途，以及为何它如此高效。
如果你希望跳过相关数学，以及演示 BM25 行为的实例，你可以去看我们伙伴的文章
[Understanding Scoring Through Examples](https://kmwllc.com/index.php/2020/03/10/understanding-scoring-through-examples/)。

## 回顾 TF-IDF

我们从头开始回顾一下 TF-IDF。想象一下我们打算搞一个搜索引擎，假定我们已经有了一个方法来匹配用户的搜索。
现在我们想要一个排分函数，它指导我们如何对文档进行排序。根据这个函数，一个文档的的排分越高，那么它出现在用户搜索结果
列表中的位置越靠前。

TF-IDF 和类似的排分函数的目标是奖励**相关性**（_relevance_）。TODO: 不地道
假如一个用户用词条（_term_）“dogs”进行搜索。如果文档 1 与“dogs”的主体的相关性比文档 2 高，
那么我们希望文档 1 的排分比文档 2 高，这样一来，我们就可以优先向用户展示更好的结果，用户就会高兴，
文档 1 的相关性排分到底有多高，这并不重要，只要排分顺序与相关性顺序一致即可。

你可能会对我们的大胆尝试感到震惊：我们尝试用数学函数来判断数百万或数十亿个文件的相关性，却不知道是谁在进行搜索，
甚至即不去读文档，也不理解用户在干嘛！这可能嘛？

我们做一个简单但是非常有帮助的假设。我们假设，一个文档包含一个词条的次数越多，它就越有可能和这个词条相关。
换句话说，我们用**词频**（_term frequency_，_TF_）——词条在文档中出现的频率——来衡量相关性。
有了这个假设，我们就可以用简单的数学来解决一个看似不可能的问题。这个假设并不完美，有时它会错的很离谱，
但多数时候它也足够好用。
所以从现在开始，我们将把词频视为一个好东西ーー一件我们想要奖励的东西。 TODO: 不地道

### TD-IDF: 第一次尝试

作为我们的排分函数的起点，我们尽可能做一些简单容易的事，把文档的排分设为它的词条出现的频率。
如果我们搜索一个词条 $T$，并计算它与文档 $D$ 的相关性，那么：

$$
\text{score}(D, T) = \text{termFrequency}(D, T)
$$

如果一个查询有多个词条，比如 “dogs and cats”，我们改怎么办嘞？我们是否要分析一下
不同词条之间的相关性，然后把每个词条的排分用一种复杂的方式混合起来呢？别急！
最简单的办法就是把每个词条的排分加一起。那我们就这么干好了。如果我们有一个多词条查询
$Q$，那么我们就令：

$$
\text{score}(D, Q) = \sum \text{score}(D,T)
$$

其中 $T$ 是 $Q$ 中的词条。

那么我们的简单排分函数怎么样嘞？很不幸，它有一些问题：

1. 长文档比短文档更有利，因为一个词条在长文档中出现的次数可能会更多，即使这些文档可能与词条没有多少相关性。我们先暂时忽略这个问题。
1. 一个查询中的所哟词条被平等地对待，这没有考虑那些词条更有意义、更重要。我们把这些词条的排分加一起的时候，无意义但频繁出现的的词条，
   比如“and”和“the”，会严重影响合并后的排分。假设你搜索“elephants and cows”。也许索引中有一个文档包含了所有三个术语
   (“elephant”、“and”、“cow”) ，但是你没有首先看到这个理想的结果，而是看到了出现“and”次数最多的文档ーー也许它有 10000 个词条。
   这种对填充词的偏好显然不是我们想要的。

### TD-IDF: 第二次尝试

为了避免被填充词干扰，我们需要一种方式来判断词条在查询中的**重要程度**（_importance_）。
因为我们的排分算法无法理解自然语言，所以我们需要一个表达重要程度的指标。我们最好的选择是**稀有度**（_rarity_）。
如果一个词条没有出现在语料库中的大多数文档中，那么无论它何时出现，我们都会猜测它的出现是有意义的。
另一方面，如果一个词条出现在我们语料库中的大多数文档中，那么词条出现在任何特定文档中都将失去其作为相关性指标的价值。

所以词频高虽然是一件好事，但是它应该被高**文档频率**（_document frequency_，_DF_）抵消一下。
文档频率是指一个词条出现在多少个文档中，我们认为它越高越不好。

所以我们的排分函数要奖励 TF，惩罚 DF，我们尝试用 TF 除 DF：

$$
\text{score}(D, T) = \cfrac{\text{termFrequency}(D,T)}{\text{docFrequency}(T)}
$$

这么做有什么问题呢？糟糕的是，DF 本身也没告诉我们什么东西。如果词条”elephant“的 DF 是 100，那么
”elephant“到底是一个稀有词条还是一个常见词条呢？这取决于语料库的大小。如果语料库中包含 100 个文档，
”elephant“就是常见词条；如果有十万个文档，”elephant“ 就稀有。

### TF-IDF: 第三次尝试

与其单独查看 DF，不如查看 N/DF，其中 N 是搜索索引或语料库的大小。
我们注意到，词条越常见，N/DF 越低
（在一个有 100 个文档的语料库中，”elephant“ 出现在了所有文档中，那么 ”elephant“ 的 N/DF = 1），
越稀有，N/DF 越高
（在一个有十万个文档的语料库中，”elephant“ 出现在了 100 个文档中，那么 ”elephant“ 的 N/DF = 1000）。
这正是我们想要的: 普通词条的排分应该低，罕见术语的排分应该高。
现在我们用下面的方式改进公式：

$$
\text{score}(D, T) = \text{termFrequency}(D,T) \times \cfrac{N}{\text{docFrequency}(T)}
$$

这已经很不错了，我们来细看一下 N/DF 的表现。
假设我们有 100 个文档，其中 1 个文档中出现了“elephant”，而 2 个文档中出现了“giraffe”。
两个词稀有度差不多，但是“elephant”的 N/DF 是 100，“giraffe”的是 50。
“elephant” 出现的频数只比 “giraffe” 多一次， N/DF 却是其 2 倍，似乎不太合理。
在语料库中多出现一个单词的惩罚似乎太高了。
直觉上，如果我们有 100 个文档，那么一个词条的 DF 是 1、2、3 还是 4 应该没有多大区别。

### TF-IDF: 第四次尝试

正如我们所看到的，当 DF 在一个非常低的范围内时，DF 的微小差异可以对 N/DF 产生显著的影响，从而对得分产生显著的影响。
当 DF 处于其范围的最低端时，我们可能希望平滑 N/DF 的下降。一种方法是取 N/DF 的**对数**。
如果需要的话，我们可以尝试在这里使用一个不同的平滑函数，但 log 很简单，它可以做我们想做的事情。

这个图表比较 N/DF 和 log(N/DF) 假设 N = 100：

![应用 log 到 IDF](/asset/img/string/ApplyingLogToIDF.png)

我们称 log(N/DF) 为词条的**反向文档频率**(_inverse document frequency_, _IDF_)。
我们的排名功能现在可以表示为 TF\*IDF 或:

$$
\text{score}(D, T) = \text{termFrequency}(D,T) \times \text{log}\cfrac{N}{\text{docFrequency}(T)}
$$

我们已经到达了 TF-IDF 的传统定义，尽管我们做了一些大胆的假设，不过该函数在实践中运行得非常好：
它在搜索引擎的成功应用方面有着悠久的历史。我们完事了吗，还能做得更好吗？

## 开发 BM25

你可能已经猜到了，我们还没准备好在 TF-IDF 停下来。
在本节中，我们将构建 BM25 功能，它可以被视为 TF-IDF 的一个改进。
我们将保留 TF\*IDF 公式的相同结构，但是我们将用这些值的细化来替换 TF 和 IDF 组件：

### 步骤一：词条饱和度

我们一直在说 TF 是一件好事，事实上我们的 TF-IDF 公式奖励它。
但是，如果一个文档包含 200 个“elephant”出现，那么它的相关性真的是包含 100 个出现的文档的两倍吗。
我们可以认为，如果“elephant”出现的次数足够多，比如说 100 次，那么文档几乎肯定是相关的，
任何进一步的提及都不会真正增加相关性的可能性。
换句话说，一旦一个文档中出现了一个词条，那么更多次的出现应该不会对得分产生重大影响。
所以我们需要一种方法来控制 TF 对我们分数的贡献。
当 TF 很小时，我们希望这个贡献快速增加，然后增加得更慢，当 TF 变得非常大时接近一个极限。

驯服 TF 的一个常见方法是取它的平方根，但这仍然是一个无界的量。我们想做一些更复杂的事情。
我们希望对 TF 对分数的贡献设定一个界限，我们希望能够控制贡献接近这个界限的速度。
如果我们有一个参数 k 可以控制饱和曲线的形状，那该多好啊。
这样的话，我们就可以用不同的 k 值来做实验，看看哪种方法对特定的语料库最有效。

为了达到这个目的，我们要使出一招。在我们的排名公式中，我们不使用原始 TF，而是使用值:

$$
\cfrac{\text{TD}}{\text{TD}+k}
$$

如果 k 被设置为 1，那么当 TF 增加 1,2,3 等等时，将生成序列 1/2,2/3,3/4,4/5,5/6 等。
注意，这个序列在开始时快速增长，然后慢慢增长，以越来越小的增量接近 1。
这就是我们想要的。现在如果我们把 k 变成 2，我们会得到 1/3,2/4,3/5,4/6，这样增长会慢一点。
下面是公式 TF/(TF + k)的图表，k = 1,2,3,4:

![TF 饱和度](/asset/img/string/TFSaturation.png)

这个 TF/(TF + k)技巧实际上是 BM25 的骨干。它让我们可以通过可调整的方式控制 TF 对分数的贡献。

### 词条饱和度与多词条查询

使用 TF/(TF+k) 来解释术语饱和度的一个幸运的副作用是，我们最终奖励完全匹配而不是部分匹配。
也就是说，我们奖励那些在多项查询中匹配更多词汇的文档，而不是那些只匹配其中一个词汇的文档。

假设“cat”和“dot”有相同的 IDF 值。
如果我们搜索“cat dog”，我们希望包含每个词条一个实例的文档比包含两个“cat”而没有“dog”的文档做得更好。
如果我们使用原始 TF，他们会得到相同的分数。但是让我们假设 k = 1 进行改进的计算。
在我们的“cat dog”文档中，“cat”和“dog”各自的 TF = 1，因此每个都将为得分贡献 TF/(TF + 1) = 1/2，总共为 1。
在我们的“cat cat”文档中，“cat”的 TF 为 2，因此它将为得分贡献 TF/(TF + 1) = 2/3。
“cat dog”文档获胜，因为“cat”和“dog”在每个文档出现一次时比“cat”在出现两次时贡献更多。

假设两个词条的 IDF 是相同的，每个词条有一个实例总比其中一个术语有两个实例要好。

### 第二步：文档长度

现在让我们回到我们第一次构建 TF-IDF 时跳过的问题：文档长度。
如果一个文档恰好非常短，并且只包含一次“elephant”，那么这是一个很好的指示器，表明“elephant”对于内容非常重要。
但是如果这个文档非常非常长，而且只提到了“elephant”一次，那么这个文档很可能与“elephant”无关。
因此，我们希望在短文档中奖励匹配，而在长文档中惩罚匹配。该怎么做呢？

首先，我们必须决定文档的长短意味着什么。
我们需要一个参考框架，所以我们将使用语料本身作为我们的参考框架。
一个简短的文档就是一个比语料库的*平均*长度短的文档。

让我们回到我们的 TF/(TF+k) 把戏。当然，随着 k 的增加，TF/(TF+k)的值减小。
为了惩罚长文档，如果文档长于平均值，我们可以调大 k，如果文档短于平均值，我们可以调小 k。
我们将通过将 k 乘以 **dl/adl** 比率来实现这一点。
在这里，dl 是文档的长度，adl 是整个语料库的平均文档长度。

当一个文档是平均长度时，dl/adl = 1，乘数根本不影响 k。
对于比平均值短的文档，我们将 k 乘以 0 到 1 之间的值，从而减少它，并增加 TF/(TF + k)。
对于长于平均值的文档，我们将 k 乘以大于 1 的值，从而增加它，并减少 TF/(TF + k)。
乘数也使我们在一个不同的 TF 饱和曲线。
较短的文档将更快地接近 TF 饱和点，而较长的文档将更渐进地接近它。

### 第三步：参数化文档长度

在上一节中，我们更新了排名函数，以考虑文档长度，但这总是一个好主意吗？
在任何特定的语料库中，我们应该把文档长度放在多大的重要性上？
有没有可能存在一些长度很重要的文档集合，而有些文档集合并不重要？
我们可以将文档长度的重要性作为第二个参数来进行实验。

我们将通过另一个技巧来实现这种可调性。
我们将添加一个新参数 b (它必须在 0 和 1 之间)。
我们不再像前面那样用 k 乘以 dl/adl，而是用以下基于 dl/adl 和 b 的值乘以 k:

$$
1 - b + b \times \cfrac{\text{dl}}{\text{adl}}
$$

这对我们有什么好处？
你可以看到如果 b 是 1，我们得到(1-1 + 1 \* dl/adl) ，这减少到我们之前的乘数 dl/adl。
另一方面，如果 b 为 0，则整个值为 1，并且根本不考虑文档长度。
当 b 从 0 加速到 1 时，乘数对 dl/adl 的变化反应更快。
下面的图表显示了当 dl/adl 增长时，当 b = 0.2 和 b = 0.8 时乘数的变化情况。

![](/asset/img/string/DocLength.png)

### 翻新：花哨版 TF

回顾一下，我们一直在修改 TF _ IDF 中的 TF 术语，使其能够响应术语饱和度和文档长度。
为了说明项饱和度，我们引入了 TF/(TF + k)技巧。
为了考虑文档长度，我们添加了(1-b + b _ dl/adl)乘数。
现在，我们不再在排名函数中使用原始的 TF，而是使用这个“花哨”版本的 TF:

$$
\cfrac{\text{TF}}{ \text{TF} + k \times (1 - b + b \times \cfrac{\text{dl}}{\text{adl}}) }
$$

回想一下，k 是控制词汇饱和曲线的旋钮，b 是控制文档长度重要性的旋钮。

事实上，这是在 BM25 中使用的 TF 的版本。祝贺你: 如果你已经跟了这么远，你现在了解所有真正有趣的东西关于 BM25。

### 第四步：花哨或不那么花哨的 IDF

我们还没有完成，但是，我们必须回到 BM25 处理文件频率的方式。
早些时候，我们将 IDF 定义为 log (N/DF) ，但 BM25 将其定义为:

$$
\text{log} \cfrac{N-\text{DF}+0.5}{\text{DF}+0.5}
$$

这有何不同？

你可能已经注意到了，我们一直在通过一系列启发式方法来开发我们的评分功能。
信息检索领域的研究人员希望将排名函数置于更严谨的理论基础之上，这样他们就可以实际证明他们的行为，而不仅仅是试验和期待最好的结果。
为了推导出理论上合理的 IDF，研究人员采用了 Robertson-Spärck Jones 权重，做了一个简化的假设，得出了
log (N-DF + 0.5)/(DF + 0.5)。我们不打算深入细节，但是我们只关注 IDF 的这种风格的实际意义。
0.5 实际上没有做很多事，所以让我们考虑 log(N-DF)/DF，它有时被称为“概率 IDF”。
在这里，我们比较我们的普通 IDF 和概率 IDF，其中 N = 10。

![](/asset/img/string/ProbabilisticIDF.png)

可以看到，概率 IDF 对于大多数文档中的词条都有大幅下降。
这可能是可取的，因为如果一个词条真的存在于 98% 的文档中，它可能是一个 stopword，
如“or”或“and”，它应该比那种出现在 70% 的文档的词条权重更低。

问题在于 log (N-DF)/DF 对于语料库中超过一半的术语是负的。（记住，log 函数在 0 到 1 之间的值为负值。）
我们不希望我们的排名函数出现负值，因为在文档中出现一个查询词汇绝不应该与检索相抵触ーー它绝不应该导致比没有该词汇更低的分数。
为了防止出现负值，Lucene 对 BM25 的实现增加了这样一个 1:

$$
\text{IDF} = \text{log} \left( 1 + \cfrac{N-\text{DF}+0.5}{\text{DF}+0.5} \right)
$$

这1可能看起来像一个无辜的修改，但它完全改变了公式的行为！
如果我们再次忘记那些讨厌的 0.5，并且我们注意到添加1和添加 DF/DF
是一样的，你可以看到公式减少到我们之前使用的 IDF 的普通版本: log(N/DF)。

$$
\begin{align}
 & \text{log} \left( 1 + \cfrac{N- \text{DF} + 0.5}{\text{DF} + 0.5}  \right) 
\\ \approx &  \text{log} \left( 1 + \cfrac{N- \text{DF}}{\text{DF}}  \right)
\\ = & \text{log} \left( \cfrac{\text{DF}}{\text{DF}} + \cfrac{N- \text{DF}}{\text{DF}}  \right)
\\ = & \text{log} \left( \cfrac{\text{DF} + N - \text{DF}}{\text{DF}} \right)
\\ = & \text{log} \left( \cfrac{N}{\text{DF}} \right)
\end{align}
$$

因此，尽管看起来 BM25使用的是一个花哨版本的 IDF，但实际上(正如在 Lucene 实施的那样) ，
它基本上使用的是传统 TF/IDF 中使用的老版本的 IDF，没有因为高 DF 值而加速下降。

## 变现

通过查看 Lucene 查询的解释输出，我们已经准备好利用我们的新理解。你会看到这样的东西:

```
“score(freq=3.0), product of:”
“idf, computed as log(1 + (N — n + 0.5) / (n + 0.5)) from:”
“tf, computed as freq / (freq + k1 * (1 — b + b * dl / avgdl)) from:”
```
我们终于准备好理解这些官样文章了。您可以看到 Lucene 正在使用 TF * IDF 产品，
其中 TF 和 IDF 有其特殊的 BM25定义。小写的 n 在这里表示 DF。
IDF 词条被认为是花哨的版本，结果与传统的 IDF，N/n。

TF 项是基于我们的饱和技巧: freq/(freq + k)。
在解释输出历史时使用 k1而不是 k ーー它来自公式中有多于一个 k 的时代。
我们一直称为原始 TF 的内容在这里表示为 freq。

我们可以看到，k1乘以一个因子，这个因子惩罚高于平均的文档长度，
同时奖励低于平均的文档长度: (1-b + b * dl/avgdl)。我们称之为 adl 的东西在这里表示为 avgdl。

当然，我们可以看到有一些参数，在 Lucene 默认设置为 k = 1.2和 b = .75。
您可能不需要调整这些，但是如果您愿意，可以这样做。

**总之，简单的 TF-IDF 奖励术语频率，惩罚文档频率。BM25超越了这一点，以解释文档长度和术语频率饱和度。**

值得注意的是，在 Lucene 引入 BM25作为版本6的默认排名函数之前，
它通过一个叫做[实用评分函数](https://www.elastic.co/guide/en/elasticsearch/guide/2.x/practical-scoring-function.html)
的东西实现了 TF-IDF，这是一组增强(包括“ coord”和字段长度标准化) ，使 TF-IDF 更像 BM25。
因此，当 Lucene 转换到 BM25时，人们可能观察到的行为差异可能没有 Lucene 一直使用纯 TF-IDF 时那么引人注目。
在任何情况下，共识是 BM25是一个改进，现在你可以看到为什么。

如果你是一个搜索工程师，Lucene 解释输出是最有可能的地方，你会遇到的细节 BM25公式。
然而，如果你深入研究理论文章或者查看[维基百科关于 BM25的文章](https://en.wikipedia.org/wiki/Okapi_BM25)，
你会看到它被写成这样一个等式:

![](/asset/img/string/bm25demystified.png)

希望这次旅行能让你更好地了解这两个最流行的搜索排名功能是如何工作的。谢谢你的配合！

## 进一步阅读

这篇文章跟随了 BM25其他一些伟大旅游的脚步。我们强烈推荐这两位:

- [BM25 The Next Generation of Lucene Relevance by Doug Turnbull](https://opensourceconnections.com/blog/2015/10/16/bm25-the-next-generation-of-lucene-relevation/)
- [Practical BM25 – Part 2: The BM25 Algorithm and its Variables by Shane Connelly](https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables)

关于排名有许多理论上的处理方法。A good starting place is “[The Probabilistic Relevance Framework: BM25 and Beyond” by Robertson and Zaragosa](http://www.staff.city.ac.uk/~sb317/papers/foundations_bm25_review.pdf). 

See also the paper “[Okapi at TREC-3](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/okapi_trec3.pdf)” where BM25 was first introduced.