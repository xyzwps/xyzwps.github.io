---
layout: ../../../layouts/MdxLayout.astro
title: 初探 Web 服务端应用
---

向前声明：本文在说 Web 应用时，是指服务端应用，而非客户端应用，除非有特殊说明。

## 单体应用

最简单的 Web 应用是单体应用。其架构大致是这样：

```
┌─────────┐      │      ┌─────────────────┐          ╔══════════╗
│ clients │<─────│─────>│ mono server app |<────────>║ database ║
└─────────┘      │      └─────────────────┘          ╚══════════╝
 client side <<< │ >>> server side
```

客户端和服务端之间通过网络连接。

服务端只有一个业务 server 实例（单体服务），它会有一个数据库用于存放数据。这个单体服务有一些特点：

1. 它非常简单。
2. 这个单体的服务挂了，整个网站就会挂掉。如果没有热更新机制，服务端升级过程会导致整个网站不可用。
3. 它无法承受较高的并发量。

这种服务架构在小型企业的内部系统中还广泛存在。

如果希望它能够承受更高的并发量，有两种常见的方式：垂直扩展和水平扩展。

## 垂直扩展

垂直扩展是通过增加单个服务器的资源来提升系统性能和容量的策略。比如增加 CPU 数量、升级内存容量、升级网络带宽、更换IO速度更快的硬盘等等。

这种扩展的方式非常简单，基本不需要应用层做改动，只要升级物理机配置就可以达到目的了。但是物理硬件配置也不是可以无限增加的，这种扩展方式受限于硬件配置的上限。

## 水平扩展

水平扩展是通过增加更多服务的数量/机器的数量来提升系统性能和容量的策略。

比如原先单体服务能扛住 1000 QPS，为了能够抗住 3000 QPS，就把这个单体服务部署三份。此时它就不再是单体应用了，而是一个多实例应用。

## 多实例应用

不管服务端是单实例还是多实例，在客户端看来，它应该像是单实例那样。换句话说，客户端发起一个请求，不管哪个服务端实例处理，应该都能得到一样的结果。

常见的作法是，在服务端会有一个代理层来统一接收客户端发来的请求，然后这个代理把请求转发给具体的实例。我们对上面的单体应用进行升级，可能就变成了这样：

```                   
                 │                       ┌──────────┐ 
                 │                  ┌──> │ server 1 |<────┐
                 │                  │    └──────────┘     │
┌─────────┐      │      ┌───────┐   │    ┌──────────┐     │     ╔══════════╗
│ clients │<─────│─────>│ proxy │<──┼──> │ server 2 |<────┼────>║ database ║
└─────────┘      │      └───────┘   │    └──────────┘     │     ╚══════════╝
                 │                  │    ┌──────────┐     │
                 │                  └──> │ server 3 |<────┘
                 │                       └──────────┘ 
 client side <<< │ >>> server side
```

因为这个代理发生在服务端，所以被称为**反向代理**。

如果一个服务被部署成多实例的，那么它就应该是**无状态的**。换句话说，增加或者减少实例数量，在业务上对客户端不会造成任何影响。

因为有代理层存在，所以就可以对服务做**滚动升级**。滚动升级是一个逐步用新版本服务替换旧版本的过程。这个过程中，新旧版本的服务会同时存在。为了避免升级过程中出现业务上的不一致，一般在升级时需要考虑**向前兼容**。

我们希望客户端发起的请求，被代理转发给具体的应用服务时，每个应用服务承受的压力尽可能一样，所以这个代理层要做一些**负载均衡**的工作。

## 负载均衡

常见的负载均衡策略有几种：

1. 轮询（Round Robin）：将请求轮流分配给每个应用服务。
2. 随机（Random）：随机选择一个应用服务来处理请求。
3. 哈希（Hash）：比如基于客户端 IP 的哈希值来选择处理请求的应用服务。
4. 加权（Weighted）：某个应用服务所在的机器配置更高，那么它被选择的概率就应该更高，就应该给与其更高的选择权重。这种方式通常配合上面三种方式一起使用，比如加权随机、加权轮询等等。

一层的负载均衡很多时候是不够的。常见的代理服务器是 nginx，单个 nginx 服务可以抗住上万的 QPS，但是上 10 万这种数量级的话就不太行了。从前到后一般有这么几层：

1. 基于域名的负载均衡：一个域名解析到多个 IP 地址。客户端发起请求时，DNS 服务器会根据负载均衡算法返回其中一个IP地址，从而将流量分散到不同的服务器上。
2. 服务器集群入口的负载均衡。商用的 F5 负载均衡器可以做到百万级 QPS；Linux 中的 LVS 可以做到 10 万级别；一些云厂商也会提供负载均衡器，比如阿里云的 SLB/ALB。
3. 服务自身的负载均衡：通常是使用 Nginx。

业务服务虽然从单实例变成了多实例，但是所有的业务代码被放到了一个应用中。在迭代的过程中，往往只是对系统中很小的一部分做迭代，但是却需要部署整个服务。
如果某个业务模块导致服务停机，那么会导致所有业务都无法为客户端提供服务的情况出现。这时，在服务端程序设计时会考虑微服务架构。

## 微服务架构

在微服务架构中，服务端代码被按照功能/业务拆分成多个独立的服务分别部署。一个电商网站服务端被拆成这么几模块：用户模块、商品模块、订单与交易模块、评价模块等。
每个模块部署成一个单独的服务。

模块之间相互独立，可以独立维护。每个模块的关注点高度内聚，功能单一，更容易理解和维护。
如果某个模块发生了故障，其他模块依然可以向客户端提供服务，而不会出现一个模块故障导致整个网站故障的情况。
根据实际使用量，每个模块可以按需动态扩展和收缩。每个微服务模块可以按需选择更加适合的技术栈。

这些东西看起来很美好，但是也带来了一系列新的问题：

1. 

TODO: